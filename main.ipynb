{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 印度vs津巴布韦！板球比赛语义分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本次板球分割任务中，我先后使用了三个模型来比较语义分割的效果，分别是U-Net、PP-LiteSeg和SegFormer。在实际检测中，PP-LiteSeg模型的预测效果还是不错的，整体情况如下：\n",
    "| 模型名称 | mIoU | Acc | Kappa | Dice |\n",
    "| -------- | -------- | -------- | -------- | -------- |\n",
    "| U-Net     | 0.5752     | 0.9700     | 0.9065     | 0.6856     |\n",
    "| PP-LiteSeg     | 0.7751     | 0.9865     | 0.9594     | 0.8632     |\n",
    "| SegFormer     | 0.7669     | 0.9877     | 0.9625     | 0.8593     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、项目背景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "语义分割是指从图像中提取特征信息，并将这些特征信息转换为对应的类别。这些类别可以是人、汽车、花朵、家具等。在计算机视觉和机器学习领域，语义分割是一个热门的研究方向，因为它在自动驾驶、室内导航、虚拟现实/增强现实等应用中有着广泛的应用。在这些应用中，我们需要准确地将图像中的每个像素映射到一个特定的类别中，以便更好地理解和处理图像。例如，在本项目中，我们可以使用语义分割模型将板球比赛场景分为击球手，投球手，检票口守门员，外野手，球，裁判员，检票口，地面和背景共9个类别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、数据集介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该数据集来自公开媒体的印度和津巴布韦之间的比赛，每 298 帧拍摄 12 帧，并替换其中的一些模糊的帧和异常值。该数据集适用于训练有关体育分析的检测模型，不过更偏向于板球。 该数据集包含9个类别：击球手，投球手，检票口守门员，外野手，球，裁判员，检票口，地面和背景。\n",
    "\n",
    "部分数据如下：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/976c1bd3cfde4c6399d01fe067af4d4db739b3bb2c1c42d0891252ab050af2dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step01： 解压数据集**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ERROR1：** \n",
    "```\n",
    "/bin/bash: -c: 行 0: 未预期的符号 `(' 附近有语法错误\n",
    "/bin/bash: -c: 行 0: `unzip /home/aistudio/data/data192893/archive (1).zip -d /home/aistudio/work/'\n",
    "```\n",
    "**SOLUTION1：** 重命名文件夹 archive(1).zip -> archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip /home/aistudio/data/data192893/archive.zip -d /home/aistudio/work/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step02：** 重命名文件夹。www.acmeai.tech ODataset 4 - Cricket Semantic Segmentation -> cricket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step03：** 分开不同后缀的文件。\n",
    "\n",
    "在/home/aistudio/work目录下新建images、jsons、labels和save文件夹。\n",
    "* images：原始图像。\n",
    "* labels：标注文件。\n",
    "\n",
    "在本次项目中只需要用到images和labels两个文件夹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T03:55:40.538071Z",
     "iopub.status.busy": "2023-03-17T03:55:40.536944Z",
     "iopub.status.idle": "2023-03-17T03:55:41.494176Z",
     "shell.execute_reply": "2023-03-17T03:55:41.492933Z",
     "shell.execute_reply.started": "2023-03-17T03:55:40.538037Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mv /home/aistudio/work/cricket/images/*.png___fuse.png /home/aistudio/work/labels/\n",
    "!mv /home/aistudio/work/cricket/images/*.png___pixel.json /home/aistudio/work/jsons/\n",
    "!mv /home/aistudio/work/cricket/images/*.png___save.png /home/aistudio/work/save/\n",
    "!mv /home/aistudio/work/cricket/images/*.png /home/aistudio/work/images/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step04：** 修改文件后缀名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd /home/aistudio/work/labels/\n",
    "!rename 's/\\.png___fuse.png/\\.png/'  ./*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 环境配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从Github下载PaddleSeg代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd /home/aistudio/\n",
    "!git clone https://github.com/PaddlePaddle/PaddleSeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行如下命令，从源码编译安装PaddleSeg包。大家对于PaddleSeg/paddleseg目录下的修改，都会立即生效，无需重新安装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd /home/aistudio/PaddleSeg/\n",
    "!pip install -r requirements.txt\n",
    "!pip install -v -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step01：** 将数据集移动到/home/aistudio/PaddleSeg/data/cricket目录下。\n",
    "\n",
    "首先要在/home/aistudio/PaddleSeg目录下新建data和cricket文件夹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T03:56:19.066621Z",
     "iopub.status.busy": "2023-03-17T03:56:19.065684Z",
     "iopub.status.idle": "2023-03-17T03:56:19.533068Z",
     "shell.execute_reply": "2023-03-17T03:56:19.531808Z",
     "shell.execute_reply.started": "2023-03-17T03:56:19.066587Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mv /home/aistudio/work/images /home/aistudio/PaddleSeg/data/cricket/\n",
    "!mv /home/aistudio/work/labels /home/aistudio/PaddleSeg/data/cricket/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd /home/aistudio/PaddleSeg/data/cricket/images/\n",
    "!rename 's/\\ (/\\_/'  ./*\n",
    "!rename 's/\\).png/\\.png/'  ./*\n",
    "%cd /home/aistudio/PaddleSeg/data/cricket/labels/\n",
    "!rename 's/\\ (/\\_/'  ./*\n",
    "!rename 's/\\).png/\\.png/'  ./*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step02：** 将彩色标注图转换成灰度标注图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先找到各个类别对应的RGB像素值，结果如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Background：#916041 对应RGB (145,96,65)\n",
    "* Ground：#e2d5de 对应RGB (226,213,222)\n",
    "* Bowler：#0018fd 对应RGB (0,24,253)\n",
    "* Batsmen：#b07a53 对应RGB (176,122,83)\n",
    "* Wicket Keeper：#8fdfa9 对应RGB (143,223,169)\n",
    "* Umpire：#e20959 对应RGB (226,9,89)\n",
    "* Fielder：#c2fe6b 对应RGB (194,254,107)\n",
    "* Ball：#5e8d38 对应RGB (94,141,56)\n",
    "* Wicket：#1e472a 对应RGB (30,71,42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，实现RGB像素值到灰度值的映射关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "Origin_SegmentationClass_path = \"/home/aistudio/PaddleSeg/data/cricket/labels\"\n",
    "Out_SegmentationClass_path = \"/home/aistudio/PaddleSeg/data/cricket/mask\"\n",
    "\n",
    "# 对应关系\n",
    "Origin_Point_Value = np.array([[145, 96, 65], [226, 213, 222], [0, 24, 253], [176, 122, 83], [143, 223, 169], [226, 9, 89], [194, 254, 107], [94, 141, 56], [30, 71, 42]])\n",
    "Out_Point_Value = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(Out_SegmentationClass_path):\n",
    "        os.makedirs(Out_SegmentationClass_path)\n",
    "    #\n",
    "    png_names = os.listdir(Origin_SegmentationClass_path) # 获得图片的文件名\n",
    "    print(\"正在遍历全部标签。\")\n",
    "    for png_name in tqdm(png_names):\n",
    "        if png_name == \".ipynb_checkpoints\":\n",
    "            continue\n",
    "        png = Image.open(os.path.join(Origin_SegmentationClass_path, png_name)) # RGB\n",
    "        w, h = png.size\n",
    "        png = np.array(png, np.uint8) # h, w, c\n",
    "        out_png = np.zeros([h, w]) # 灰度 h, w\n",
    "\n",
    "        for map_idx, rgb in enumerate(Origin_Point_Value):\n",
    "            idx = np.where(\n",
    "                (png[..., 0] == rgb[0]) & (png[..., 1] == rgb[1]) & (png[..., 2] == rgb[2]))\n",
    "            out_png[idx] = map_idx\n",
    "\n",
    "        # print(\"out_png:\", out_png.shape)\n",
    "\n",
    "        out_png = Image.fromarray(np.array(out_png, np.uint8)) # 再次转化为Image进行保存\n",
    "        out_png.save(os.path.join(Out_SegmentationClass_path, png_name))\n",
    "\n",
    "\n",
    "    # 统计输出，各个像素点的值的个数\n",
    "    print(\"正在统计输出的图片每个像素点的数量。\")\n",
    "    classes_nums = np.zeros([256], np.int32)\n",
    "    for png_name in tqdm(png_names):\n",
    "        if png_name == \".ipynb_checkpoints\":\n",
    "            continue\n",
    "        png_file_name = os.path.join(Out_SegmentationClass_path, png_name)\n",
    "        if not os.path.exists(png_file_name):\n",
    "            raise ValueError(\"未检测到标签图片%s，请查看具体路径下文件是否存在以及后缀是否为png。\" % (png_file_name))\n",
    "\n",
    "        png = np.array(Image.open(png_file_name), np.uint8)\n",
    "        classes_nums += np.bincount(np.reshape(png, [-1]), minlength=256)\n",
    "\n",
    "    print(\"打印像素点的值与数量。\")\n",
    "    print('-' * 37)\n",
    "    print(\"| %15s | %15s |\" % (\"Key\", \"Value\"))\n",
    "    print('-' * 37)\n",
    "    for i in range(256):\n",
    "        if classes_nums[i] > 0:\n",
    "            print(\"| %15s | %15s |\" % (str(i), str(classes_nums[i])))\n",
    "            print('-' * 37)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，为了判断转换的结果是否正确，我们可以使用PaddleSeg提供的转换工具，将灰度标注图转换成伪彩色标注图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/data/gray2pseudo_color.py /home/aistudio/PaddleSeg/data/cricket/mask /home/aistudio/PaddleSeg/data/cricket/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理结果如下：\n",
    "* 左上：板球比赛原图。\n",
    "* 右上：板球比赛原标注图。\n",
    "* 左下：转换得到的训练用的灰度标注图\n",
    "* 右下：通过PaddleSeg的转换工具得到的伪彩色标注图，用于判断转换结果是否正确。\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e318430e6559443dafaf507618a98405404a8c92d7194f77b4dd32763722df67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step03：** 切分数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd /home/aistudio/PaddleSeg/\n",
    "!python tools/data/split_dataset_list.py /home/aistudio/PaddleSeg/data/cricket images mask --format \"png\" \"png\" --split 0.7 0.3 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PP-LiteSeg**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PP-LiteSeg**提出三个创新模块：\n",
    "* 解码模块（FLD）调整解码模块中通道数，平衡编码模块和解码模块的计算量。\n",
    "* 注意力融合模块（UAFM）加强特征表示。\n",
    "* 简易金字塔池化模块（SPPM）减小中间特征图的通道数、移除跳跃连接。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c81da81e9e464c0f8b8262fc06bd93b63190ad161c984a368af4161eff2c3af6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好配置文件后，我们使用tools/train.py脚本进行模型训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/train.py \\\n",
    "    --config configs/pp_liteseg/pp_liteseg_stdc2_cityscapes_1024x512_scale1.0_160k.yml \\\n",
    "    --save_dir output/pp_liteseg \\\n",
    "    --save_interval 2000 \\\n",
    "    --num_workers 2 \\\n",
    "    --do_eval \\\n",
    "    --use_vdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果训练中断，我们可以恢复训练，避免从头开始训练。通过给train.py脚本设置resume_model输入参数，加载中断前最近一次保存的模型信息，恢复训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/train.py \\\n",
    "    --config configs/pp_liteseg/pp_liteseg_stdc2_cityscapes_1024x512_scale1.0_160k.yml \\\n",
    "    --save_dir output/pp_liteseg \\\n",
    "    --save_interval 2000 \\\n",
    "    --resume_model output/pp_liteseg/iter_52000 \\\n",
    "    --num_workers 2 \\\n",
    "    --do_eval \\\n",
    "    --use_vdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数如下：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/13a21214f12f419ca2cbcaeae68e3f8126e718dfb5324229bf6a05af567cbf86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**U-Net**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-Net网络结构因为形似字母“U”而得名，最早是在医学影像的细胞分割任务中提出，结构简单适合处理小数量级的数据集。比较于FCN网络的像素相加，U-Net是对通道进行concat操作，保留上下文信息的同时，加强了它们之间的语义联系。整体是一个Encode-Decode的结构，如下图所示。\n",
    "* 知识点1:下采样Encode包括conv和max pool，上采样Decode包括up-conv和conv。\n",
    "* 知识点2:U-Net特点在于灰色箭头，利用通道融合使上下文信息紧密联系起来。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/8b7f98a211c14be6b5075cd1ae6e39f1693643857e7649caacc339356f59d8cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/train.py \\\n",
    "    --config configs/unet/unet_cityscapes_1024x512_160k.yml \\\n",
    "    --save_dir output/unet \\\n",
    "    --save_interval 2000 \\\n",
    "    --num_workers 2 \\\n",
    "    --do_eval \\\n",
    "    --use_vdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/train.py \\\n",
    "    --config configs/unet/unet_cityscapes_1024x512_160k.yml \\\n",
    "    --save_dir output/unet \\\n",
    "    --save_interval 2000 \\\n",
    "    --resume_model output/unet/iter_56000 \\\n",
    "    --num_workers 2 \\\n",
    "    --do_eval \\\n",
    "    --use_vdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SegFormer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SegFormer是一种将Transformer和轻量级的MLP相结合的语义分割框架。该框架的优势在于：\n",
    "* 知识点1：层次化的transformer编码器/MiT，生成不同尺度特征；\n",
    "* 知识点2：轻量的全MLP解码器，融合不同层级特征。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4312d3e6da87497ea9a91a3ad19522b44af5ca808f1049bf98efaf74c21f7f32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/train.py \\\n",
    "    --config configs/segformer/segformer_b5_cityscapes_1024x512_160k.yml \\\n",
    "    --save_dir output/segformer \\\n",
    "    --save_interval 2000 \\\n",
    "    --num_workers 2 \\\n",
    "    --do_eval \\\n",
    "    --use_vdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/train.py \\\n",
    "    --config configs/segformer/segformer_b5_cityscapes_1024x512_160k.yml \\\n",
    "    --save_dir output/segformer \\\n",
    "    --save_interval 2000 \\\n",
    "    --resume_model output/segformer/iter_34000 \\\n",
    "    --num_workers 2 \\\n",
    "    --do_eval \\\n",
    "    --use_vdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "恢复训练中，大家可能会遇到一个问题，那就是日志文件是分割开的，接下来我们可以通过以下代码合并日志文件。\n",
    "\n",
    "1. 将所有的x.log文件拷贝到一个logs目录下。\n",
    "2. 将代码中的target_dir设置为上一步logs的根目录，运行后，会生成一个与logs同级的目录merge，merge下的x.log文件即包含了完整训练数据。\n",
    "3. 可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from visualdl import LogReader, LogWriter\n",
    "\n",
    "def trans_vdlrecords_to_txt(vdl_file_path):\n",
    "    txt_path = vdl_file_path.replace('.log', '.txt')\n",
    "    reader = LogReader(file_path=vdl_file_path)\n",
    "    tags = reader.get_tags()\n",
    "    scalar = tags.get('scalar')\n",
    "    if scalar is not None:\n",
    "        fo = open(txt_path, \"w\")\n",
    "        fo.write(f'tags:{tags}')\n",
    "\n",
    "        for tag in scalar:\n",
    "            fo.write(f'\\n------------{tag}------------\\n')\n",
    "            data = reader.get_data('scalar', tag)\n",
    "            fo.write(f'The Last One is {str(data[-1])}')\n",
    "            fo.write(str(data))\n",
    "\n",
    "        fo.close()\n",
    "\n",
    "\n",
    "def merge_vdlrecords(vdl_file_path, last_step_dict, writer=None):\n",
    "    reader = LogReader(file_path=vdl_file_path)\n",
    "    tags = reader.get_tags()\n",
    "    scalar = tags.get('scalar')\n",
    "\n",
    "    if scalar is not None:\n",
    "        print(f'tags:{tags}')\n",
    "        data = None\n",
    "        for tag in scalar:\n",
    "            data = reader.get_data('scalar', tag)\n",
    "            for e in data:\n",
    "                curr_last_step = last_step_dict[tag] if tag in last_step_dict else -1\n",
    "                if e.id > curr_last_step:\n",
    "                    writer.add_scalar(tag=tag, step=e.id, value=e.value)\n",
    "            last_step_dict[tag] = data[-1].id\n",
    "            print(f'{vdl_file_path} {tag} last_id is {last_step_dict[tag]}')\n",
    "    return last_step_dict\n",
    "\n",
    "def do_merge(target_dir):\n",
    "    logdir = target_dir + '/merge'\n",
    "    writer = LogWriter(logdir=logdir)\n",
    "    last_step_dict = {}\n",
    "    print('called1')\n",
    "    try:\n",
    "        for path, dir_list, file_list in os.walk(target_dir + '/logs'):\n",
    "            print('called2', file_list)\n",
    "            file_list.sort() \n",
    "            for file_name in file_list:\n",
    "                if file_name.endswith('.log'):\n",
    "                    log_path = os.path.join(path, file_name)\n",
    "                    print(log_path)\n",
    "                    last_step = merge_vdlrecords(log_path, last_step_dict, writer)\n",
    "    except Exception as err:\n",
    "        print(f'error {erro}')\n",
    "    finally:\n",
    "        writer.close()\n",
    "\n",
    "def do_trans(_dir):\n",
    "    for path, dir_list, file_list in os.walk(_dir):\n",
    "        for file_name in file_list:\n",
    "            if file_name.endswith('.log'):\n",
    "                log_path = os.path.join(path, file_name)\n",
    "                print(log_path)\n",
    "                trans_vdlrecords_to_txt(log_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    target_dir = '/home/aistudio/PaddleSeg/output/segformer/'\n",
    "    do_merge(target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 模型评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练完成后，大家可以使用评估脚本tools/val.py来评估模型的精度，即对配置文件中的验证数据集进行测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PP-LiteSeg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/val.py \\\n",
    "       --config configs/pp_liteseg/pp_liteseg_stdc2_cityscapes_1024x512_scale1.0_160k.yml \\\n",
    "       --model_path output/pp_liteseg/best_model/model.pdparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指标如下：\n",
    "* [EVAL] #Images: 89 mIoU: 0.7751 Acc: 0.9865 Kappa: 0.9594 Dice: 0.8632\n",
    "* [EVAL] Class IoU: [0.9485 0.9878 0.7535 0.8408 0.7275 0.9158 0.7254 0.4405 0.6366]\n",
    "* [EVAL] Class Precision: [0.9588 0.9972 0.9282 0.9318 0.8178 0.9601 0.7737 0.6414 0.7756]\n",
    "* [EVAL] Class Recall: [0.9888 0.9906 0.8001 0.8959 0.8682 0.952  0.9208 0.5845 0.7803]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**U-Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/val.py \\\n",
    "       --config configs/unet/unet_cityscapes_1024x512_160k.yml \\\n",
    "       --model_path output/unet/best_model/model.pdparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指标如下：\n",
    "* [EVAL] #Images: 89 mIoU: 0.5752 Acc: 0.9700 Kappa: 0.9065 Dice: 0.6856\n",
    "* [EVAL] Class IoU: [0.8739 0.9779 0.5385 0.6238 0.4768 0.7272 0.4314 0.     0.5272]\n",
    "* [EVAL] Class Precision: [0.985  0.9806 0.8682 0.7056 0.5954 0.7795 0.5945 0.     0.7845]\n",
    "* [EVAL] Class Recall: [0.8857 0.9972 0.5864 0.8433 0.7053 0.9156 0.6113 0.     0.6165]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SegFormer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/val.py \\\n",
    "       --config configs/segformer/segformer_b5_cityscapes_1024x512_160k.yml \\\n",
    "       --model_path output/segformer/best_model/model.pdparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指标如下：\n",
    "* [EVAL] #Images: 89 mIoU: 0.7669 Acc: 0.9877 Kappa: 0.9625 Dice: 0.8593\n",
    "* [EVAL] Class IoU: [0.959  0.991  0.6543 0.8017 0.7272 0.915  0.6649 0.4981 0.6908]\n",
    "* [EVAL] Class Precision: [0.9877 0.9943 0.8839 0.863  0.8486 0.9723 0.7471 0.6818 0.8416]\n",
    "* [EVAL] Class Recall: [0.9706 0.9967 0.7158 0.9186 0.8356 0.9395 0.8581 0.6491 0.7941]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以通过tools/predict.py脚本是来进行可视化预测，命令格式如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/predict.py \\\n",
    "       --config configs/pp_liteseg/pp_liteseg_stdc2_cityscapes_1024x512_scale1.0_160k.yml \\\n",
    "       --model_path output/pp_liteseg/best_model/model.pdparams \\\n",
    "       --image_path data/cricket/images \\\n",
    "       --save_dir output/result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "部分可视化结果如下：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/91c6ee903ad04283a8eba5c6340a5dbb6ef5f2966b9c4ad1bd84e8068e9c3faa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当分割目标比较清晰的时候，分割效果还是很好的；但当分割目标较小时，分割效果还有待加强。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 模型导出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行如下命令，导出预测模型，保存在output/inference_model目录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/export.py \\\n",
    "       --config configs/pp_liteseg/pp_liteseg_stdc2_cityscapes_1024x512_scale1.0_160k.yml \\\n",
    "       --model_path output/pp_liteseg/best_model/model.pdparams \\\n",
    "       --save_dir output/inference_model/pp_liteseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/export.py \\\r\n",
    "       --config configs/unet/unet_cityscapes_1024x512_160k.yml \\\r\n",
    "       --model_path output/unet/best_model/model.pdparams \\\r\n",
    "       --save_dir output/inference_model/unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/export.py \\\r\n",
    "       --config configs/segformer/segformer_b5_cityscapes_1024x512_160k.yml \\\r\n",
    "       --model_path output/segformer/best_model/model.pdparams \\\r\n",
    "       --save_dir output/inference_model/segformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 FastDeploy快速部署"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**环境准备：** 本项目的部署环节主要用到的套件为飞桨部署工具FastDeploy，因此我们先安装FastDeploy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install fastdeploy-gpu-python -f https://www.paddlepaddle.org.cn/whl/fastdeploy.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**部署模型：**\n",
    "\n",
    "导入飞桨部署工具FastDepoy包，创建Runtimeoption，具体实现如下代码所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T08:16:43.843073Z",
     "iopub.status.busy": "2023-03-19T08:16:43.841556Z",
     "iopub.status.idle": "2023-03-19T08:16:44.625888Z",
     "shell.execute_reply": "2023-03-19T08:16:44.624708Z",
     "shell.execute_reply.started": "2023-03-19T08:16:43.843012Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import fastdeploy as fd\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T08:16:46.520711Z",
     "iopub.status.busy": "2023-03-19T08:16:46.519306Z",
     "iopub.status.idle": "2023-03-19T08:16:46.526450Z",
     "shell.execute_reply": "2023-03-19T08:16:46.525296Z",
     "shell.execute_reply.started": "2023-03-19T08:16:46.520668Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_option(device='cpu', use_trt=False):\n",
    "    option = fd.RuntimeOption()\n",
    "\n",
    "    if device.lower() == \"gpu\":\n",
    "        option.use_gpu()\n",
    "\n",
    "    if use_trt:\n",
    "        option.use_trt_backend()\n",
    "        option.set_trt_input_shape(\"x\", [1, 3, 1080, 1920])\n",
    "        option.set_trt_input_shape(\"scale_factor\", [1, 2])\n",
    "\n",
    "    return option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配置模型路径，创建Runtimeoption，指定部署设备和后端推理引擎，代码实现如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 配置模型路径\n",
    "model_path = '/home/aistudio/PaddleSeg/output/inference_model'\n",
    "image_path = '/home/aistudio/PaddleSeg/data/cricket/images/2022-08-24_134.png'\n",
    "model_file = os.path.join(model_path, \"model.pdmodel\")\n",
    "params_file = os.path.join(model_path, \"model.pdiparams\")\n",
    "config_file = os.path.join(model_path, \"deploy.yaml\")\n",
    "\n",
    "# 创建RuntimeOption\n",
    "runtime_option = build_option(device='gpu', use_trt=False)\n",
    "\n",
    "# 创建PPYOLOE模型\n",
    "model = fd.vision.segmentation.PaddleSegModel(model_file,\n",
    "                                              params_file,\n",
    "                                              config_file,\n",
    "                                              runtime_option=runtime_option)\n",
    "\n",
    "# 预测图片检测结果\n",
    "im = cv2.imread(image_path)\n",
    "result = model.predict(im.copy())\n",
    "print(result)\n",
    "\n",
    "# 预测结果可视化\n",
    "vis_im = fd.vision.vis_segmentation(im, result, weight=0.5)\n",
    "cv2.imwrite(\"/home/aistudio/work/visualized_result.jpg\", vis_im)\n",
    "print(\"Visualized result save in ./visualized_result.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果如下：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d7ac6086f9c94891b432684c120abda5446eaad87b274a7eb5ebada98280aef4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 总结提高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本次板球分割任务中，我先后使用了三个模型来比较语义分割的效果，分别是U-Net、PP-LiteSeg和SegFormer。整体情况如下：\n",
    "\n",
    "| 模型名称 | mIoU | Acc | Kappa | Dice |\n",
    "| -------- | -------- | -------- | -------- | -------- |\n",
    "| U-Net     | 0.5752     | 0.9700     | 0.9065     | 0.6856     |\n",
    "| PP-LiteSeg     | 0.7751     | 0.9865     | 0.9594     | 0.8632     |\n",
    "| SegFormer     | 0.7669     | 0.9877     | 0.9625     | 0.8593     |\n",
    "\n",
    "PP-LiteSeg和SegFormer的分割情况是相对比较好的，U-Net的情况相对较差。后续可以进一步调参或更换模型尝试能否达到更好的预测效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作者简介：Submerge. 江苏某大学大三学生 人工智能专业 [主页链接](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/2365489) 欢迎互关！\n",
    "\n",
    "飞桨导师：周昆阳 [喜乐多多多](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/297029) 在此感谢。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
